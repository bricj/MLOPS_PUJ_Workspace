{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83210d46-b5f6-4399-a66e-11e27d135453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "## download the dataset\n",
    "# Directory of the raw data files\n",
    "_data_root = './data/Diabetes'\n",
    "# Path to the raw training data\n",
    "_data_filepath = os.path.join(_data_root, 'Diabetes.csv')\n",
    "# Download data\n",
    "os.makedirs(_data_root, exist_ok=True)\n",
    "if not os.path.isfile(_data_filepath):\n",
    "    #https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/\n",
    "    url = 'https://docs.google.com/uc?export= \\\n",
    "    download&confirm={{VALUE}}&id=1k5-1caezQ3zWJbKaiMULTGq-3sz6uThC'\n",
    "    r = requests.get(url, allow_redirects=True, stream=True)\n",
    "    open(_data_filepath, 'wb').write(r.content)\n",
    "\n",
    "df_diabetes = pd.read_csv(_data_filepath )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36128fa1-5681-4121-8cd4-e54530b5e8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight',\n",
       "       'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
       "       'time_in_hospital', 'payer_code', 'medical_specialty',\n",
       "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
       "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
       "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
       "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
       "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
       "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
       "       'glyburide-metformin', 'glipizide-metformin',\n",
       "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
       "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diabetes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5761d60d-fb50-401e-878d-8e1195fe15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_diabetes_data(df, data_filepath=None):\n",
    "    \"\"\"\n",
    "    Preprocesses the diabetes dataset by handling categorical and numerical variables,\n",
    "    creating derived features, and preparing the target variable.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame or None\n",
    "        The diabetes dataframe to preprocess. If None, data will be loaded from data_filepath.\n",
    "    data_filepath : str or None\n",
    "        Path to the CSV file containing the diabetes data. Used only if df is None.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X : pandas.DataFrame\n",
    "        Preprocessed features dataframe\n",
    "    y : pandas.Series\n",
    "        Target variable (readmitted)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Load data if dataframe not provided\n",
    "    if df is None:\n",
    "        if data_filepath is None:\n",
    "            raise ValueError(\"Either df or data_filepath must be provided\")\n",
    "        df = pd.read_csv(data_filepath)\n",
    "    \n",
    "    # Define column categories\n",
    "    ids_cols = ['encounter_id', 'patient_nbr']\n",
    "    \n",
    "    categorical_cols = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', \n",
    "                       'admission_source_id', 'payer_code', 'medical_specialty',\n",
    "                       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "                       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "                       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "                       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
    "                       'glyburide-metformin', 'glipizide-metformin',\n",
    "                       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "                       'metformin-pioglitazone', 'change', 'readmitted', 'diag_1', 'diag_2', 'diag_3',\n",
    "                       'diabetesMed', 'max_glu_serum', 'A1Cresult']\n",
    "    \n",
    "    numerical_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications',\n",
    "                     'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses']\n",
    "    \n",
    "    # Split dataframe into categorical and numerical parts\n",
    "    df_diabetes_cat = df[categorical_cols]\n",
    "    df_diabetes_num = df[numerical_cols]\n",
    "    \n",
    "    # Process target variable\n",
    "    y = df_diabetes['readmitted'].copy()\n",
    "    y = y.apply(lambda x: 'YES' if (x == '<30') else 'NO')\n",
    "    \n",
    "    # Process numerical variables\n",
    "    df_diabetes_num['service_utilization'] = (df_diabetes_num['number_outpatient'] + \n",
    "                                             df_diabetes_num['number_emergency'] + \n",
    "                                             df_diabetes_num['number_inpatient'])\n",
    "    \n",
    "    # Process categorical variables\n",
    "    no_representative_cat = ['repaglinide', 'nateglinide', 'chlorpropamide', 'acetohexamide', \n",
    "                            'glipizide', 'tolbutamide', 'acarbose', 'miglitol', 'troglitazone',\n",
    "                            'tolazamide', 'glyburide-metformin', 'glipizide-metformin',\n",
    "                            'glimepiride-pioglitazone', 'metformin-rosiglitazone', \n",
    "                            'metformin-pioglitazone', 'payer_code', \n",
    "                            'medical_specialty', 'diag_2', 'diag_3']\n",
    "    \n",
    "    df_diabetes_cat_depured = df_diabetes_cat.drop(no_representative_cat, axis=1)\n",
    "    X_cat = df_diabetes_cat_depured.drop('readmitted', axis=1)\n",
    "    \n",
    "    # Fill missing values\n",
    "    X_cat = X_cat.fillna('?')\n",
    "    \n",
    "    # Process diagnosis codes\n",
    "    X_cat['diag_1'] = X_cat['diag_1'].apply(lambda x: level1_diag1(x))\n",
    "    \n",
    "    # Group admission source ID\n",
    "    admission_source_mapping = {\n",
    "        2: 1, 3: 1,  # Group to 1\n",
    "        5: 4, 6: 4, 8: 4, 10: 4, 18: 4, 22: 4, 25: 4, 26: 4,  # Group to 4\n",
    "        15: 9, 17: 9, 20: 9, 21: 9,  # Group to 9\n",
    "        13: 11, 14: 11, 23: 11, 24: 11  # Group to 11\n",
    "    }\n",
    "    X_cat['admission_source_id'] = X_cat['admission_source_id'].replace(admission_source_mapping)\n",
    "    \n",
    "    # Group admission type ID\n",
    "    admission_type_mapping = {\n",
    "        2: 1, 7: 1, 4: 1,  # Group to Emergency (1)\n",
    "        6: 5, 8: 5  # Group to Not available (5)\n",
    "    }\n",
    "    X_cat['admission_type_id'] = X_cat['admission_type_id'].replace(admission_type_mapping)\n",
    "    \n",
    "    # Group discharge disposition ID\n",
    "    discharge_mapping_1 = {6: 1, 8: 1, 13: 1, 19: 1, 20: 1}  # Group to 1\n",
    "    discharge_mapping_2 = {3: 2, 4: 2, 5: 2, 9: 2, 10: 2, 12: 2, 14: 2, 22: 2, 23: 2, 24: 2}  # Group to 2\n",
    "    discharge_mapping_15 = {16: 15, 17: 15, 27: 15, 28: 15, 29: 15, 30: 15}  # Group to 15\n",
    "    discharge_mapping_18 = {25: 18, 26: 18}  # Group to 18\n",
    "    \n",
    "    discharge_mapping = {**discharge_mapping_1, **discharge_mapping_2, **discharge_mapping_15, **discharge_mapping_18}\n",
    "    X_cat['discharge_disposition_id'] = X_cat['discharge_disposition_id'].replace(discharge_mapping)\n",
    "    \n",
    "    # Combine categorical and numerical features\n",
    "    X = pd.concat([X_cat, df_diabetes_num], axis=1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def level1_diag1(x):\n",
    "    \"\"\"\n",
    "    Maps diagnosis codes to categorical levels\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : int or str\n",
    "        Diagnosis code\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    int\n",
    "        Mapped diagnosis category (0-8)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    if isinstance(x, (int, float)) and not np.isnan(x):\n",
    "        x = int(x)\n",
    "        if (x >= 390 and x < 460) or (np.floor(x) == 785):\n",
    "            return 1\n",
    "        elif (x >= 460 and x < 520) or (np.floor(x) == 786):\n",
    "            return 2\n",
    "        elif (x >= 520 and x < 580) or (np.floor(x) == 787):\n",
    "            return 3\n",
    "        elif (np.floor(x) == 250):\n",
    "            return 4\n",
    "        elif (x >= 800 and x < 1000):\n",
    "            return 5\n",
    "        elif (x >= 710 and x < 740):\n",
    "            return 6\n",
    "        elif (x >= 580 and x < 630) or (np.floor(x) == 788):\n",
    "            return 7\n",
    "        elif (x >= 140 and x < 240):\n",
    "            return 8\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Transform \n",
    "\n",
    "def create_preprocessing_pipeline(X, cat_cols=None, num_cols=None):\n",
    "    \"\"\"\n",
    "    Creates a preprocessing pipeline for transforming categorical and numerical variables\n",
    "    using scikit-learn's ColumnTransformer.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pandas.DataFrame\n",
    "        DataFrame containing the features to transform\n",
    "    cat_cols : list or None\n",
    "        List of categorical column names. If None, uses default list.\n",
    "    num_cols : list or None\n",
    "        List of numerical column names. If None, uses default list.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    preprocessor : ColumnTransformer\n",
    "        Fitted ColumnTransformer object for preprocessing the data\n",
    "    X_transformed : numpy.ndarray\n",
    "        Transformed feature matrix\n",
    "    \"\"\"\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "    \n",
    "    # Define default columns if not provided\n",
    "    if cat_cols is None:\n",
    "        cat_cols = ['race', 'gender', 'age', 'admission_type_id',\n",
    "                   'discharge_disposition_id', 'admission_source_id', 'metformin',\n",
    "                   'glimepiride', 'glyburide', 'pioglitazone', 'rosiglitazone', 'examide',\n",
    "                   'citoglipton', 'insulin', 'change', 'diag_1', 'diabetesMed',\n",
    "                   'max_glu_serum', 'A1Cresult']\n",
    "    \n",
    "    if num_cols is None:\n",
    "        num_cols = ['time_in_hospital', 'num_lab_procedures',\n",
    "                   'num_procedures', 'num_medications', 'number_outpatient',\n",
    "                   'number_emergency', 'number_inpatient', 'number_diagnoses', \n",
    "                   'service_utilization']\n",
    "    \n",
    "    # Validate that the columns exist in the DataFrame\n",
    "    missing_cat_cols = [col for col in cat_cols if col not in X.columns]\n",
    "    missing_num_cols = [col for col in num_cols if col not in X.columns]\n",
    "    \n",
    "    if missing_cat_cols:\n",
    "        raise ValueError(f\"Categorical columns not found in DataFrame: {missing_cat_cols}\")\n",
    "    \n",
    "    if missing_num_cols:\n",
    "        raise ValueError(f\"Numerical columns not found in DataFrame: {missing_num_cols}\")\n",
    "    \n",
    "    # Pipeline for numerical columns\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Pipeline for categorical columns\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Create column transformer\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, num_cols),\n",
    "        (\"cat\", categorical_pipeline, cat_cols)\n",
    "    ])\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    return preprocessor, X_transformed\n",
    "\n",
    "def perform_undersampling_from_transformed(X_transformed, y, random_state=42, sampling_strategy=1.0):\n",
    "    \"\"\"\n",
    "    Performs undersampling on already transformed data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_transformed : numpy.ndarray\n",
    "        Transformed feature matrix\n",
    "    y : pandas.Series or numpy.ndarray\n",
    "        Target variable (class labels)\n",
    "    random_state : int, default=42\n",
    "        Controls the randomization of the algorithm\n",
    "    sampling_strategy : float or str, default=1.0\n",
    "        If float, specifies the ratio of minority to majority class samples.\n",
    "        If 'auto' or 'majority', the majority class is resampled to match the minority.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X_transformed_resampled : numpy.ndarray\n",
    "        Undersampled transformed feature matrix\n",
    "    y_resampled : numpy.ndarray or pandas.Series\n",
    "        Undersampled target variable\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Check if y is a pandas Series\n",
    "    is_pandas_series = isinstance(y, pd.Series)\n",
    "    if is_pandas_series:\n",
    "        y_name = y.name\n",
    "    \n",
    "    # Get array representation\n",
    "    y_array = y.values if is_pandas_series else y\n",
    "    \n",
    "    # Find indices of each class\n",
    "    unique_classes = np.unique(y_array)\n",
    "    class_indices = {}\n",
    "    for cls in unique_classes:\n",
    "        class_indices[cls] = np.where(y_array == cls)[0]\n",
    "    \n",
    "    # Display class distribution before resampling\n",
    "    print(\"Class distribution before undersampling:\")\n",
    "    for cls, indices in class_indices.items():\n",
    "        print(f\"  Class {cls}: {len(indices)} samples\")\n",
    "    \n",
    "    # Determine target count for majority class\n",
    "    if len(unique_classes) != 2:\n",
    "        raise ValueError(\"This function only supports binary classification problems\")\n",
    "    \n",
    "    # Find majority and minority classes\n",
    "    class_counts = [len(class_indices[cls]) for cls in unique_classes]\n",
    "    majority_class_idx = np.argmax(class_counts)\n",
    "    minority_class_idx = 1 - majority_class_idx\n",
    "    \n",
    "    majority_class = unique_classes[majority_class_idx]\n",
    "    minority_class = unique_classes[minority_class_idx]\n",
    "    \n",
    "    minority_count = len(class_indices[minority_class])\n",
    "    majority_count = len(class_indices[majority_class])\n",
    "    \n",
    "    # Calculate target sample count for majority class\n",
    "    if sampling_strategy == 'auto' or sampling_strategy == 'majority':\n",
    "        target_majority_count = minority_count\n",
    "    elif isinstance(sampling_strategy, (int, float)):\n",
    "        # sampling_strategy is ratio of minority:majority\n",
    "        target_majority_count = int(minority_count / sampling_strategy)\n",
    "    else:\n",
    "        raise ValueError(\"sampling_strategy must be 'auto', 'majority', or a number\")\n",
    "    \n",
    "    # Undersample majority class\n",
    "    np.random.seed(random_state)\n",
    "    selected_majority_indices = np.random.choice(\n",
    "        class_indices[majority_class], \n",
    "        size=min(target_majority_count, majority_count), \n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    # Combine with minority class indices\n",
    "    selected_indices = np.concatenate([selected_majority_indices, class_indices[minority_class]])\n",
    "    \n",
    "    # Get resampled data\n",
    "    X_transformed_resampled = X_transformed[selected_indices]\n",
    "    y_resampled = y_array[selected_indices]\n",
    "    \n",
    "    # Display class distribution after resampling\n",
    "    unique_resampled, counts_resampled = np.unique(y_resampled, return_counts=True)\n",
    "    print(\"Class distribution after undersampling:\")\n",
    "    for cls, count in zip(unique_resampled, counts_resampled):\n",
    "        print(f\"  Class {cls}: {count} samples\")\n",
    "    \n",
    "    # Preserve pandas Series type if input was a Series\n",
    "    if is_pandas_series:\n",
    "        y_resampled = pd.Series(y_resampled, name=y_name)\n",
    "    \n",
    "    return X_transformed_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "984084fa-c48d-40b8-8495-0ef0a5df5965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "858f4890-a940-404e-a287-bbaa592fbe63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66/206035937.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_diabetes_num['service_utilization'] = (df_diabetes_num['number_outpatient'] +\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess_diabetes_data(df_diabetes)\n",
    "Preprocessor, X_transformed = create_preprocessing_pipeline(X, cat_cols=None, num_cols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7576c17-16fe-4823-b7e2-2a4c007daea5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before undersampling:\n",
      "  Class NO: 90409 samples\n",
      "  Class YES: 11357 samples\n",
      "Class distribution after undersampling:\n",
      "  Class NO: 11357 samples\n",
      "  Class YES: 11357 samples\n"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = perform_undersampling_from_transformed(X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c32b30-104e-449b-9ab6-12831323701e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "436e5a7d-6468-4fc8-9b15-34a2dd4c5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_transformed_data(X_transformed, y, model=None, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a model using already transformed data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_transformed : numpy.ndarray\n",
    "        Transformed feature matrix\n",
    "    y : pandas.Series or numpy.ndarray\n",
    "        Target variable\n",
    "    model : estimator or None\n",
    "        Scikit-learn estimator to use. If None, uses RandomForestClassifier.\n",
    "    test_size : float\n",
    "        Proportion of the dataset to include in the test split\n",
    "    random_state : int\n",
    "        Random state for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model : estimator\n",
    "        Fitted model\n",
    "    results : dict\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create model if not provided\n",
    "    if model is None:\n",
    "        model = RandomForestClassifier(random_state=random_state)\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_transformed, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, pos_label=\"YES\"),\n",
    "        \"recall\": recall_score(y_test, y_pred, pos_label=\"YES\"),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, pos_label=\"YES\")\n",
    "    }\n",
    "    \n",
    "    # Calculate ROC AUC if probability estimates are available\n",
    "    if y_pred_proba is not None:\n",
    "        results[\"roc_auc\"] = roc_auc_score(y_test == \"YES\", y_pred_proba)\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "# DespuÃ©s de obtener X_transformed_resampled y y_resampled:\n",
    "model, results = train_evaluate_transformed_data(X_resampled, y_resampled)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fea5a108-7f73-4e82-8dfe-4c596da25fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6033749082905356, 'precision': 0.6054523666866387, 'recall': 0.5931904901673026, 'f1_score': 0.5992587101556709, 'roc_auc': 0.6400755883013569}\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
